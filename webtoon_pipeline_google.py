"""
ì›¹íˆ° ìë™ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ v4.0 (Google Gemini API)
1. PDF/PSD/PSB â†’ PNG ë³€í™˜
2. PNG â†’ ì»· ë¶„ë¦¬ (íŒ¨ë„ ë‹¨ìœ„, ì–‘ë°©í–¥ ì—¬ë°± ê°ì§€)
3. ì»· ì‚¬ì „ ë¶„ë¥˜ (YOLO + OCR + í…ìŠ¤íŠ¸ ë¶„ë¥˜) - NEW
4. ë§í’ì„  ì œê±° (ì„ íƒì  Google Gemini API í˜¸ì¶œ)

v4.0 ìˆ˜ì •:
- ì‚¬ì „ ë¶„ë¥˜ ê¸°ëŠ¥ ì¶”ê°€ (analyze_cuts_for_bubble)
- ì„ íƒì  API í˜¸ì¶œ ê¸°ëŠ¥ ì¶”ê°€ (remove_speech_bubbles_selective)
- API ë¹„ìš© ì ˆê° (íš¨ê³¼ìŒ/ë§í’ì„  ì—†ìŒ â†’ ì›ë³¸ ë³µì‚¬)

ì‚¬ìš©ë²•:
  pip install google-genai PyMuPDF Pillow numpy psd-tools ultralytics pytesseract
  python webtoon_pipeline_google.py input.pdf --api-key YOUR_GOOGLE_API_KEY
"""
import os
import sys
import time
import json
import shutil
from pathlib import Path
from datetime import datetime
from io import BytesIO
from PIL import Image
import numpy as np

# ==========================================
# ğŸ”‘ Google API í‚¤ í•˜ë“œì½”ë”© (ì—¬ê¸°ì— ì…ë ¥)
# ==========================================
HARDCODED_API_KEY = "" 
# ==========================================

# Google GenAI
try:
    from google import genai
    from google.genai import types
    HAS_GENAI = True
except ImportError:
    HAS_GENAI = False
    print("âš ï¸ google-genai ë¯¸ì„¤ì¹˜: pip install google-genai")

# PDF ì²˜ë¦¬
try:
    import fitz  # PyMuPDF
    HAS_FITZ = True
except ImportError:
    HAS_FITZ = False
    print("âš ï¸ PyMuPDF ë¯¸ì„¤ì¹˜: pip install PyMuPDF")

# PSD/PSB ì²˜ë¦¬
try:
    from psd_tools import PSDImage
    HAS_PSD = True
except ImportError:
    HAS_PSD = False
    print("âš ï¸ psd-tools ë¯¸ì„¤ì¹˜: pip install psd-tools")

# ë§í’ì„  í”„ë¡œì„¸ì„œ
try:
    from webtoon_bubble_processor import WebtoonBubbleProcessor
    HAS_BUBBLE_PROCESSOR = True
except ImportError:
    HAS_BUBBLE_PROCESSOR = False
    print("âš ï¸ webtoon_bubble_processor ë¯¸ì„¤ì¹˜")


# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (ëŒ€ì‚¬ ë§í’ì„ ë§Œ ì œê±° - í™˜ê° ë°©ì§€ ê°•í™”)
DEFAULT_PROMPT = """<instruction_set>
  <task_definition>
    You are a highly specialized image editing AI. Your mission is to perform **surgical removal** of speech bubbles while guaranteeing the **absolute preservation** of all character art and background details.
    The previous execution critically failed by deleting characters. You must correct this. **Your primary goal is to protect the characters.**
  </task_definition>

  <critical_constraints description="RULES THAT CANNOT BE BROKEN. VIOLATION = FAILURE.">
    1.  **CHARACTER PROTECTION IS PARAMOUNT:** Under NO circumstances shall any part of a character's body, hair, clothing, or face be removed, erased, blurred, or altered. The inpainting process must **never** replace character art with background texture.
    2.  **SFX & Background Text are SACRED:** Do not touch any stylized sound effect text (e.g., 'ìª½', 'ë¶€ìŠ¤ìŠ¤', 'ì¿µ') or any text that is part of the background art (signs, labels). These are immutable parts of the image.
    3.  **NO Global Changes:** Do not alter the overall color, lighting, or composition of the image.
  </critical_constraints>

  <remove_targets description="Identify and remove ONLY these specific elements">
    1.  **Speech Bubble Layer:** The white or colored shapes that contain dialogue text.
    2.  **Bubble Borders & Tails:** The black outlines and the pointed tails connecting bubbles to characters.
    3.  **Standard Dialogue Text:** The standard font text inside the bubbles.
  </remove_targets>

  <inpainting_rules description="How to fill the removed areas SAFELY">
    1.  **Reveal, Don't Replace:** When a speech bubble covers a character, your job is to **reveal** the character art that would logically be underneath it. You must reconstruct the hidden parts of the character (hair, clothes, skin) based on the visible surrounding art. **Do NOT fill character areas with wall/bed patterns.**
    2.  **Background-Only Inpainting:** Only when a bubble is entirely over a simple background (e.g., a wall or sky) should you use texture synthesis to fill it with the surrounding background pattern.
    3.  **Contextual Intelligence:** Before inpainting a pixel, determine: "Is this pixel part of a character or the background?" If it's a character, reconstruct the character. If it's background, reconstruct the background.

  <output_format>
    Return ONLY the final, processed image where speech bubbles are gone, but characters and SFX are perfectly intact.
  </output_format>
</instruction_set>"""


class WebtoonPipelineGoogle:
    """Google Gemini API ê¸°ë°˜ ì›¹íˆ° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    # ì´ë¯¸ì§€ ìƒì„±/í¸ì§‘ ì§€ì› ëª¨ë¸
    MODELS = {
        'flash': 'gemini-2.5-flash-image',           # GA, ì•ˆì •ì , ë¹ ë¦„
        'pro': 'gemini-3-pro-image-preview',         # ìµœì‹  ê³ í’ˆì§ˆ
    }
    
    # ì§€ì› íŒŒì¼ í˜•ì‹
    SUPPORTED_FORMATS = {
        'pdf': ['.pdf'],
        'psd': ['.psd', '.psb'],
        'image': ['.png', '.jpg', '.jpeg', '.webp']
    }
    
    def __init__(self, api_key=None, model='flash', require_api=True):
        """
        Args:
            api_key: Google API í‚¤
            model: 'flash' ë˜ëŠ” 'pro'
            require_api: Trueë©´ API í‚¤ í•„ìˆ˜, Falseë©´ ë³€í™˜/ë¶„ë¦¬ë§Œ ì‚¬ìš© ê°€ëŠ¥
        """
        # API í‚¤ ìš°ì„ ìˆœìœ„: ì¸ì > í•˜ë“œì½”ë”© > í™˜ê²½ë³€ìˆ˜
        self.api_key = (
            api_key or 
            HARDCODED_API_KEY or 
            os.getenv('GOOGLE_API_KEY') or 
            os.getenv('GEMINI_API_KEY')
        )
        
        self.client = None
        self.model_name = self.MODELS.get(model, self.MODELS['flash'])
        
        # APIê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ê²€ì¦
        if require_api:
            if not self.api_key:
                raise ValueError("GOOGLE_API_KEY í•„ìš”. https://aistudio.google.com ì—ì„œ ë°œê¸‰")
            
            if not HAS_GENAI:
                raise ImportError("google-genai í•„ìš”: pip install google-genai")
            
            self.client = genai.Client(api_key=self.api_key)
            print(f"âœ“ Google Gemini API ì´ˆê¸°í™” ì™„ë£Œ")
            print(f"  ëª¨ë¸: {self.model_name}")
        else:
            print(f"âœ“ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (ë³€í™˜/ë¶„ë¦¬ ëª¨ë“œ)")
        
        self.stats = {
            'start_time': None,
            'end_time': None,
            'input_files': 0,
            'png_files': 0,
            'cuts_total': 0,
            'bubbles_removed': 0,
            'api_calls': 0,
            'api_skipped': 0,
            'errors': []
        }
        
        # ë§í’ì„  í”„ë¡œì„¸ì„œ (ì‚¬ì „ ë¶„ë¥˜ìš©)
        self.bubble_processor = None
    
    def _get_file_type(self, file_path):
        """íŒŒì¼ íƒ€ì… íŒë³„"""
        ext = Path(file_path).suffix.lower()
        for file_type, extensions in self.SUPPORTED_FORMATS.items():
            if ext in extensions:
                return file_type
        return None
    
    # ========================================
    # ë‹¨ê³„ 1: PDF/PSD/PSB â†’ PNG ë³€í™˜
    # ========================================
    
    def pdf_to_png(self, pdf_path, output_dir, dpi=300):
        """PDF â†’ PNG ë³€í™˜"""
        if not HAS_FITZ:
            raise ImportError("PyMuPDF í•„ìš”: pip install PyMuPDF")
        
        pdf_path = Path(pdf_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"  PDF: {pdf_path.name}")
        
        png_files = []
        
        doc = fitz.open(str(pdf_path))
        total_pages = len(doc)
        
        for page_num in range(total_pages):
            page = doc[page_num]
            zoom = dpi / 72
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat, alpha=False)
            
            output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.png"
            output_path = output_dir / output_filename
            pix.save(str(output_path))
            
            png_files.append(str(output_path))
            print(f"    [{page_num + 1}/{total_pages}] {output_filename}")
        
        doc.close()
        return png_files
    
    def psd_to_png(self, psd_path, output_dir):
        """PSD/PSB â†’ PNG ë³€í™˜"""
        if not HAS_PSD:
            raise ImportError("psd-tools í•„ìš”: pip install psd-tools")
        
        psd_path = Path(psd_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"  PSD/PSB: {psd_path.name}")
        
        psd = PSDImage.open(str(psd_path))
        
        # í•©ì„± ì´ë¯¸ì§€ (ëª¨ë“  ë ˆì´ì–´ ë³‘í•©)
        composite = psd.composite()
        
        if composite.mode != 'RGB':
            composite = composite.convert('RGB')
        
        output_filename = f"{psd_path.stem}.png"
        output_path = output_dir / output_filename
        composite.save(str(output_path))
        
        print(f"    â†’ {output_filename} ({composite.width}x{composite.height})")
        
        return [str(output_path)]
    
    def image_to_png(self, image_path, output_dir):
        """ì´ë¯¸ì§€ íŒŒì¼ â†’ PNG ë³µì‚¬/ë³€í™˜"""
        image_path = Path(image_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"  ì´ë¯¸ì§€: {image_path.name}")
        
        img = Image.open(str(image_path))
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        output_filename = f"{image_path.stem}.png"
        output_path = output_dir / output_filename
        img.save(str(output_path))
        
        print(f"    â†’ {output_filename}")
        
        return [str(output_path)]
    
    def convert_to_png(self, input_files, output_dir, dpi=300):
        """ë‹¤ì–‘í•œ í˜•ì‹ â†’ PNG ë³€í™˜"""
        print("\n" + "=" * 60)
        print("ë‹¨ê³„ 1: ì…ë ¥ íŒŒì¼ â†’ PNG ë³€í™˜")
        print("=" * 60)
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if isinstance(input_files, (str, Path)):
            input_files = [input_files]
        
        print(f"ì…ë ¥: {len(input_files)}ê°œ íŒŒì¼")
        
        all_png_files = []
        
        for input_file in input_files:
            input_path = Path(input_file)
            
            if not input_path.exists():
                print(f"  âš ï¸ íŒŒì¼ ì—†ìŒ: {input_path}")
                continue
            
            file_type = self._get_file_type(input_path)
            
            try:
                if file_type == 'pdf':
                    png_files = self.pdf_to_png(input_path, output_dir, dpi=dpi)
                elif file_type == 'psd':
                    png_files = self.psd_to_png(input_path, output_dir)
                elif file_type == 'image':
                    png_files = self.image_to_png(input_path, output_dir)
                else:
                    print(f"  âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {input_path.suffix}")
                    continue
                
                all_png_files.extend(png_files)
                self.stats['input_files'] += 1
                
            except Exception as e:
                print(f"  âš ï¸ ë³€í™˜ ì˜¤ë¥˜: {e}")
                self.stats['errors'].append(f"{input_path.name}: {e}")
        
        self.stats['png_files'] = len(all_png_files)
        
        print(f"\nâœ“ ì™„ë£Œ: {len(all_png_files)}ê°œ PNG")
        return all_png_files
    
    # ========================================
    # ë‹¨ê³„ 2: PNG â†’ ì»· ë¶„ë¦¬ (ì–‘ë°©í–¥ ì—¬ë°± ê°ì§€)
    # ========================================
    
    def split_into_cuts(self, png_files, output_dir, 
                       min_gap_height=150, quality_threshold=0.5,
                       std_threshold=15, remove_empty_edges=False,
                       min_cut_height=200):
        """
        PNG â†’ ì»· ë¶„ë¦¬ (9:16 ë¹„ìœ¨ ê¸°ì¤€ ê³ ì •)
        
        9:16 = ê°€ë¡œ:ì„¸ë¡œ ë¹„ìœ¨
        ìµœëŒ€ ë†’ì´ = ë„ˆë¹„ Ã— (16/9)
        
        Args:
            min_gap_height: ìµœì†Œ ì—¬ë°± ë†’ì´ (ê¸°ë³¸: 150px) - íŒ¨ë„ ê°„ êµ¬ë¶„ì„ 
            quality_threshold: ì—¬ë°± í’ˆì§ˆ (ê¸°ë³¸: 0.5) - ë¯¸ì‚¬ìš©
            std_threshold: ê· ì¼ ì˜ì—­ í‘œì¤€í¸ì°¨ ì„ê³„ê°’ (ê¸°ë³¸: 15) - ë¯¸ì‚¬ìš©
            remove_empty_edges: ë¹ˆ ì—¬ë°± ì œê±° (ê¸°ë³¸: False) - ë¯¸ì‚¬ìš©
            min_cut_height: ìµœì†Œ ì»· ë†’ì´ (ê¸°ë³¸: 200px) - ë¯¸ì‚¬ìš©
        
        Note:
            9:16 ë¹„ìœ¨ ê³ ì • - ìµœëŒ€ ë†’ì´ = ë„ˆë¹„ Ã— 16/9
            ì´ë¯¸ì§€ í›¼ì† ë°©ì§€ - ë¶„ë¦¬ì ì— ì—¬ë°± ì—†ìœ¼ë©´ í†µì§¸ë¡œ ìœ ì§€
        """
        print("\n" + "=" * 60)
        print("PNG â†’ ì»· ë¶„ë¦¬ (9:16 ë¹„ìœ¨ ê¸°ì¤€)")
        print("=" * 60)
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ë‚´ë¶€ ì—¬ë°± ê¸°ì¤€ (ê³ ì •ê°’)
        min_internal_gap = 10
        min_panel_gap = 40
        
        if isinstance(png_files, (str, Path)):
            png_files = [png_files]
        
        print(f"ì…ë ¥: {len(png_files)}ê°œ íŒŒì¼")
        print(f"ë¹„ìœ¨: 9:16 (ìµœëŒ€ ë†’ì´ = ë„ˆë¹„ Ã— 16/9)")
        print(f"ë‚´ë¶€ ì—¬ë°± ê¸°ì¤€: {min_internal_gap}px")
        print(f"íŒ¨ë„ ì—¬ë°± ê¸°ì¤€: {min_panel_gap}px")
        
        all_cuts = []
        
        for file_idx, png_file in enumerate(png_files, 1):
            filename = Path(png_file).name
            print(f"\n[{file_idx}/{len(png_files)}] {filename}")
            
            try:
                img = Image.open(png_file)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                img_array = np.array(img)
                height, width = img_array.shape[:2]
                
                # 9:16 ë¹„ìœ¨ ê¸°ì¤€ ìµœëŒ€ ë†’ì´ ê³„ì‚°
                max_cut_height = int(width * 16 / 9)
                
                print(f"  í¬ê¸°: {width}x{height}")
                print(f"  9:16 ê¸°ì¤€ ìµœëŒ€ ë†’ì´: {max_cut_height}px")
                
                # ì—¬ë°± ê°ì§€
                all_gaps = self._detect_gaps_for_ratio(img_array, min_internal_gap)
                print(f"  ê°ì§€ëœ ì—¬ë°±: {len(all_gaps)}ê°œ")
                
                # 9:16 ë¹„ìœ¨ ê¸°ì¤€ ì»· ë¶„ë¦¬
                cuts_boundaries = self._split_by_ratio(
                    all_gaps, height, max_cut_height, min_panel_gap
                )
                
                print(f"  ë¶„ë¦¬ ê²½ê³„: {cuts_boundaries}")
                
                # ì»· ì €ì¥
                page_stem = Path(png_file).stem
                cuts_saved = 0
                
                for i in range(len(cuts_boundaries) - 1):
                    start_y = cuts_boundaries[i]
                    end_y = cuts_boundaries[i + 1]
                    cut_height = end_y - start_y
                    
                    if cut_height < 30:  # ë„ˆë¬´ ì‘ì€ ì»· ìŠ¤í‚µ
                        continue
                    
                    cut_img = img.crop((0, start_y, width, end_y))
                    cuts_saved += 1
                    cut_filename = f"{page_stem}_cut_{cuts_saved:02d}.png"
                    cut_path = output_dir / cut_filename
                    cut_img.save(str(cut_path))
                    all_cuts.append(str(cut_path))
                    
                    status = "âš ï¸ ì´ˆê³¼" if cut_height > max_cut_height else "âœ“"
                    print(f"    ì»· {cuts_saved}: y={start_y}~{end_y} ({cut_height}px) {status}")
                
                print(f"  â†’ {cuts_saved}ê°œ ì»· ìƒì„±")
                
            except Exception as e:
                print(f"  âš ï¸ ì˜¤ë¥˜: {e}")
                self.stats['errors'].append(f"{filename}: {e}")
        
        self.stats['cuts_total'] = len(all_cuts)
        
        print(f"\nâœ“ ì™„ë£Œ: ì´ {len(all_cuts)}ê°œ ì»·")
        return all_cuts
    
    def _detect_gaps_for_ratio(self, img_array, min_height=10):
        """
        9:16 ë¹„ìœ¨ ë¶„ë¦¬ìš© ì—¬ë°± ê°ì§€
        
        Args:
            img_array: RGB ì´ë¯¸ì§€ ë°°ì—´
            min_height: ìµœì†Œ ì—¬ë°± ë†’ì´
        
        Returns:
            ì—¬ë°± ë¦¬ìŠ¤íŠ¸ [{'start', 'end', 'mid', 'height', 'type'}, ...]
        """
        height = img_array.shape[0]
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° í–‰ë³„ í†µê³„
        gray = np.mean(img_array, axis=2)
        row_brightness = np.mean(gray, axis=1)
        row_std = np.std(gray, axis=1)
        
        # ì—¬ë°± íŒì • (ì–´ë‘ìš´ìƒ‰: ë°ê¸° < 50, ë°ì€ìƒ‰: ë°ê¸° > 240, std < 15)
        is_dark_gap = (row_brightness < 50) & (row_std < 15)
        is_light_gap = (row_brightness > 240) & (row_std < 15)
        is_gap = is_dark_gap | is_light_gap
        
        # ì—°ì† ì—¬ë°± ì˜ì—­ ì°¾ê¸°
        gaps = []
        in_gap = False
        gap_start = 0
        
        for i in range(height):
            if is_gap[i] and not in_gap:
                gap_start = i
                in_gap = True
            elif not is_gap[i] and in_gap:
                gap_height = i - gap_start
                if gap_height >= min_height:
                    avg_brightness = np.mean(row_brightness[gap_start:i])
                    gaps.append({
                        'start': gap_start,
                        'end': i - 1,
                        'mid': (gap_start + i - 1) // 2,
                        'height': gap_height,
                        'type': 'black' if avg_brightness < 50 else 'white'
                    })
                in_gap = False
        
        # ë§ˆì§€ë§‰ ì—¬ë°± ì²˜ë¦¬
        if in_gap:
            gap_height = height - gap_start
            if gap_height >= min_height:
                avg_brightness = np.mean(row_brightness[gap_start:height])
                gaps.append({
                    'start': gap_start,
                    'end': height - 1,
                    'mid': (gap_start + height - 1) // 2,
                    'height': gap_height,
                    'type': 'black' if avg_brightness < 50 else 'white'
                })
        
        return gaps
    
    def _split_by_ratio(self, all_gaps, total_height, max_cut_height, min_panel_gap):
        """
        ë¹„ìœ¨ ê¸°ì¤€ìœ¼ë¡œ ì»· ë¶„ë¦¬ ê²½ê³„ ê³„ì‚°
        
        ë¡œì§:
        1. í˜„ì¬ ìœ„ì¹˜ì—ì„œ max_cut_height ë²”ìœ„ ë‚´ì˜ ì—¬ë°±ë“¤ í™•ì¸
        2. ë²”ìœ„ ë‚´ ë§ˆì§€ë§‰ ì—¬ë°±(ê°€ì¥ ì•„ë˜ìª½)ì—ì„œ ë¶„ë¦¬
        3. ì—¬ë°±ì´ ì—†ìœ¼ë©´ ê³ ì • ë†’ì´ë¡œ ê°•ì œ ë¶„í• 
        
        Args:
            all_gaps: ëª¨ë“  ì—¬ë°± ë¦¬ìŠ¤íŠ¸
            total_height: ì „ì²´ ì´ë¯¸ì§€ ë†’ì´
            max_cut_height: ìµœëŒ€ ì»· ë†’ì´ (9:16 ê¸°ì¤€)
            min_panel_gap: íŒ¨ë„ êµ¬ë¶„ ìµœì†Œ ì—¬ë°±
        
        Returns:
            ë¶„ë¦¬ ê²½ê³„ì  ë¦¬ìŠ¤íŠ¸
        """
        # ì—¬ë°±ì´ ì—†ìœ¼ë©´ ê³ ì • ë†’ì´ë¡œ ë¶„í• 
        if not all_gaps:
            print(f"    âš ï¸ ì—¬ë°± ì—†ìŒ, ê³ ì • ë†’ì´({max_cut_height}px)ë¡œ ë¶„í• ")
            boundaries = [0]
            y = max_cut_height
            while y < total_height:
                boundaries.append(y)
                y += max_cut_height
            boundaries.append(total_height)
            return boundaries
        
        # íŒ¨ë„ êµ¬ë¶„ìš© ì—¬ë°±ë§Œ í•„í„°ë§ (í° ì—¬ë°±)
        panel_gaps = [g for g in all_gaps if g['height'] >= min_panel_gap]
        
        # ìƒë‹¨ ì—¬ë°± ì²˜ë¦¬: ì²« ì—¬ë°±ì´ ë§¨ ìœ„ì— ìˆìœ¼ë©´ ê·¸ ì´í›„ë¶€í„° ì‹œì‘
        start_y = 0
        if panel_gaps and panel_gaps[0]['start'] < 50:
            start_y = panel_gaps[0]['end'] + 1
            panel_gaps = panel_gaps[1:]
        
        # í•˜ë‹¨ ì—¬ë°± ì²˜ë¦¬: ë§ˆì§€ë§‰ ì—¬ë°±ì´ ë§¨ ì•„ë˜ë©´ ê·¸ ì´ì „ê¹Œì§€
        end_y = total_height
        if panel_gaps and panel_gaps[-1]['end'] > total_height - 50:
            end_y = panel_gaps[-1]['start']
            panel_gaps = panel_gaps[:-1]
        
        # ë¶„ë¦¬ ê²½ê³„ ê³„ì‚°
        boundaries = [start_y]
        current_pos = start_y
        
        while current_pos < end_y:
            # í˜„ì¬ ìœ„ì¹˜ì—ì„œ max_cut_height ë²”ìœ„ ê³„ì‚°
            target_end = min(current_pos + max_cut_height, end_y)
            
            # ë‚¨ì€ ë†’ì´ê°€ max_cut_height ì´í•˜ë©´ ëê¹Œì§€ í¬í•¨
            if end_y - current_pos <= max_cut_height:
                boundaries.append(end_y)
                break
            
            # ë²”ìœ„ ë‚´ ì—¬ë°± ì°¾ê¸° (í˜„ì¬ ìœ„ì¹˜ ì´í›„, target_end ì´ì „)
            gaps_in_range = [g for g in all_gaps 
                           if g['mid'] > current_pos and g['mid'] <= target_end]
            
            if gaps_in_range:
                # ë²”ìœ„ ë‚´ ê°€ì¥ ì•„ë˜ìª½ ì—¬ë°±ì—ì„œ ë¶„ë¦¬
                best_gap = max(gaps_in_range, key=lambda g: g['mid'])
                split_point = best_gap['mid']
                boundaries.append(split_point)
                current_pos = split_point
            else:
                # ë²”ìœ„ ë‚´ ì—¬ë°± ì—†ìŒ - ë‹¤ìŒ ì—¬ë°± ì°¾ê¸°
                gaps_after = [g for g in all_gaps 
                             if g['mid'] > target_end]
                
                if gaps_after:
                    # ë‹¤ìŒ ì—¬ë°±ê¹Œì§€ í™•ì¥ (ìµœëŒ€ 2ë°°ê¹Œì§€ë§Œ)
                    next_gap = min(gaps_after, key=lambda g: g['mid'])
                    if next_gap['mid'] - current_pos <= max_cut_height * 2:
                        split_point = next_gap['mid']
                        boundaries.append(split_point)
                        current_pos = split_point
                        print(f"    âš ï¸ ë²”ìœ„ ë‚´ ì—¬ë°± ì—†ìŒ, ë‹¤ìŒ ì—¬ë°±ê¹Œì§€ í™•ì¥: {split_point}px")
                    else:
                        # ë„ˆë¬´ ë©€ë©´ ê³ ì • ë†’ì´ë¡œ ë¶„í• 
                        split_point = current_pos + max_cut_height
                        boundaries.append(split_point)
                        current_pos = split_point
                        print(f"    âš ï¸ ì—¬ë°± ë„ˆë¬´ ë©‚, ê³ ì • ë†’ì´ë¡œ ë¶„í• : {split_point}px")
                else:
                    # ì—¬ë°±ì´ ì „í˜€ ì—†ìŒ - ëê¹Œì§€ í¬í•¨
                    boundaries.append(end_y)
                    print(f"    âš ï¸ ë‚¨ì€ ì—¬ë°± ì—†ìŒ, ëê¹Œì§€ í¬í•¨")
                    break
        
        # ë§ˆì§€ë§‰ ê²½ê³„ ì¶”ê°€
        if boundaries[-1] != end_y:
            boundaries.append(end_y)
        
        return boundaries
    
    # ========================================
    # ë‹¨ê³„ 3: ì»· ì‚¬ì „ ë¶„ë¥˜ (NEW)
    # ========================================
    
    def init_bubble_processor(self, model_path=None, confidence_threshold=0.15,
                               use_heuristic=True, use_ocr=True, use_text_filter=True):
        """ë§í’ì„  í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”"""
        if not HAS_BUBBLE_PROCESSOR:
            print("âš ï¸ webtoon_bubble_processorë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            self.bubble_processor = WebtoonBubbleProcessor(
                model_path=model_path,
                confidence_threshold=confidence_threshold,
                use_heuristic=use_heuristic,
                use_ocr=use_ocr,
                use_text_filter=use_text_filter
            )
            print("âœ“ ë§í’ì„  í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âš ï¸ ë§í’ì„  í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_cuts_for_bubble(self, cuts_dir, model_path=None, 
                                 confidence_threshold=0.15,
                                 use_heuristic=True,
                                 use_ocr=True,
                                 use_text_filter=True,
                                 verbose=True):
        """
        ì»· ë””ë ‰í† ë¦¬ ë¶„ì„ (ì‚¬ì „ ë¶„ë¥˜)
        
        Args:
            cuts_dir: ì»· ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬
            model_path: YOLO ëª¨ë¸ ê²½ë¡œ
            confidence_threshold: ê°ì§€ ì„ê³„ê°’
            use_heuristic: íœ´ë¦¬ìŠ¤í‹± ë³´ì¡° ê°ì§€ ì‚¬ìš©
            use_ocr: OCR ì‚¬ìš©
            use_text_filter: í…ìŠ¤íŠ¸ í•„í„°ë§ ì‚¬ìš©
            verbose: ìƒì„¸ ì¶œë ¥
        
        Returns:
            {
                'process': [íŒŒì¼ëª…...],           # API ì²˜ë¦¬ ëŒ€ìƒ
                'skip_sfx_only': [íŒŒì¼ëª…...],     # íš¨ê³¼ìŒë§Œ (ì›ë³¸ ë³µì‚¬)
                'skip_no_bubble': [íŒŒì¼ëª…...],    # ë§í’ì„  ì—†ìŒ (ì›ë³¸ ë³µì‚¬)
                'skip_no_text': [íŒŒì¼ëª…...],      # í…ìŠ¤íŠ¸ ì—†ìŒ (ì›ë³¸ ë³µì‚¬)
                'details': {íŒŒì¼ëª…: {...}, ...},  # ìƒì„¸ ë¶„ì„ ê²°ê³¼
                'stats': {...}                    # í†µê³„
            }
        """
        print("\n" + "=" * 60)
        print("ë‹¨ê³„ 3: ì»· ì‚¬ì „ ë¶„ë¥˜ (ë§í’ì„  ê°ì§€)")
        print("=" * 60)
        
        cuts_dir = Path(cuts_dir)
        
        if not cuts_dir.exists():
            print(f"âš ï¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {cuts_dir}")
            return None
        
        # ì»· íŒŒì¼ ëª©ë¡
        cut_files = sorted(cuts_dir.glob("*.png"))
        
        if not cut_files:
            print(f"âš ï¸ ì»· íŒŒì¼ ì—†ìŒ: {cuts_dir}")
            return None
        
        print(f"ë¶„ì„ ëŒ€ìƒ: {len(cut_files)}ê°œ ì»·")
        
        # í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        if self.bubble_processor is None:
            if not self.init_bubble_processor(
                model_path=model_path,
                confidence_threshold=confidence_threshold,
                use_heuristic=use_heuristic,
                use_ocr=use_ocr,
                use_text_filter=use_text_filter
            ):
                # í”„ë¡œì„¸ì„œ ì—†ìœ¼ë©´ ëª¨ë‘ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ
                print("âš ï¸ ë§í’ì„  í”„ë¡œì„¸ì„œ ì—†ìŒ - ëª¨ë“  ì»·ì„ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ ì„¤ì •")
                return {
                    'process': [f.name for f in cut_files],
                    'skip_sfx_only': [],
                    'skip_no_bubble': [],
                    'skip_no_text': [],
                    'details': {f.name: {'action': 'process', 'reason': 'no_processor'} for f in cut_files},
                    'stats': {
                        'total': len(cut_files),
                        'to_process': len(cut_files),
                        'skip_sfx_only': 0,
                        'skip_no_bubble': 0,
                        'skip_no_text': 0,
                        'filter_rate': 0
                    }
                }
        
        # ë¶„ë¥˜ ê²°ê³¼
        result = {
            'process': [],
            'skip_sfx_only': [],
            'skip_no_bubble': [],
            'skip_no_text': [],
            'details': {},
            'stats': {}
        }
        
        # ê° ì»· ë¶„ì„
        for idx, cut_file in enumerate(cut_files):
            if verbose:
                print(f"  [{idx + 1}/{len(cut_files)}] {cut_file.name}...", end=" ")
            
            try:
                analysis = self.bubble_processor.process(str(cut_file))
                
                action = analysis.get('action', 'process')
                result['details'][cut_file.name] = {
                    'action': action,
                    'has_bubble': analysis.get('has_bubble', False),
                    'has_dialogue': analysis.get('has_dialogue', False),
                    'bubble_count': analysis.get('bubble_count', 0),
                    'bubble_confidence': analysis.get('bubble_confidence', 0),
                    'detection_method': analysis.get('detection_method', 'none'),
                    'text_analysis': analysis.get('text_analysis')
                }
                
                if action == 'process':
                    result['process'].append(cut_file.name)
                    if verbose:
                        ta = analysis.get('text_analysis', {})
                        print(f"âœ… ì²˜ë¦¬ëŒ€ìƒ (ëŒ€í™”:{ta.get('dialogue_count', 0)}ê°œ)")
                elif action == 'skip_sfx_only':
                    result['skip_sfx_only'].append(cut_file.name)
                    if verbose:
                        ta = analysis.get('text_analysis', {})
                        print(f"ğŸ”Š íš¨ê³¼ìŒë§Œ ({ta.get('sfx_count', 0)}ê°œ)")
                elif action == 'skip_no_bubble':
                    result['skip_no_bubble'].append(cut_file.name)
                    if verbose:
                        print(f"â¬œ ë§í’ì„  ì—†ìŒ")
                elif action == 'skip_no_text':
                    result['skip_no_text'].append(cut_file.name)
                    if verbose:
                        print(f"ğŸ“ í…ìŠ¤íŠ¸ ì—†ìŒ")
                else:
                    result['process'].append(cut_file.name)
                    if verbose:
                        print(f"â“ ê¸°íƒ€ â†’ ì²˜ë¦¬ëŒ€ìƒ")
                        
            except Exception as e:
                # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ
                result['process'].append(cut_file.name)
                result['details'][cut_file.name] = {
                    'action': 'process',
                    'error': str(e)
                }
                if verbose:
                    print(f"âš ï¸ ì˜¤ë¥˜ â†’ ì²˜ë¦¬ëŒ€ìƒ: {e}")
        
        # í†µê³„
        total = len(cut_files)
        to_process = len(result['process'])
        skip_sfx = len(result['skip_sfx_only'])
        skip_no_bubble = len(result['skip_no_bubble'])
        skip_no_text = len(result['skip_no_text'])
        skip_total = skip_sfx + skip_no_bubble + skip_no_text
        filter_rate = (skip_total / total * 100) if total > 0 else 0
        
        result['stats'] = {
            'total': total,
            'to_process': to_process,
            'skip_sfx_only': skip_sfx,
            'skip_no_bubble': skip_no_bubble,
            'skip_no_text': skip_no_text,
            'filter_rate': filter_rate
        }
        
        print(f"\nğŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
        print(f"   âœ… ì²˜ë¦¬ ëŒ€ìƒ: {to_process}ê°œ")
        print(f"   ğŸ”Š íš¨ê³¼ìŒë§Œ: {skip_sfx}ê°œ")
        print(f"   â¬œ ë§í’ì„  ì—†ìŒ: {skip_no_bubble}ê°œ")
        print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì—†ìŒ: {skip_no_text}ê°œ")
        print(f"   ğŸ’° API ì ˆê°ë¥ : {filter_rate:.1f}%")
        
        return result
    
    def save_analysis_result(self, cuts_dir, analysis_result):
        """ë¶„ì„ ê²°ê³¼ JSON ì €ì¥"""
        cuts_dir = Path(cuts_dir)
        analysis_file = cuts_dir.parent / "2_cuts_analysis.json"
        
        save_data = {
            'timestamp': datetime.now().isoformat(),
            'cuts_dir': str(cuts_dir),
            'classification': {
                'process': analysis_result['process'],
                'skip_sfx_only': analysis_result['skip_sfx_only'],
                'skip_no_bubble': analysis_result['skip_no_bubble'],
                'skip_no_text': analysis_result.get('skip_no_text', [])
            },
            'details': analysis_result['details'],
            'stats': analysis_result['stats'],
            'user_modified': False
        }
        
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ ë¶„ì„ ê²°ê³¼ ì €ì¥: {analysis_file}")
        return str(analysis_file)
    
    def load_analysis_result(self, cuts_dir):
        """ë¶„ì„ ê²°ê³¼ JSON ë¡œë“œ"""
        cuts_dir = Path(cuts_dir)
        analysis_file = cuts_dir.parent / "2_cuts_analysis.json"
        
        if not analysis_file.exists():
            return None
        
        with open(analysis_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return {
            'process': data['classification']['process'],
            'skip_sfx_only': data['classification']['skip_sfx_only'],
            'skip_no_bubble': data['classification']['skip_no_bubble'],
            'skip_no_text': data['classification'].get('skip_no_text', []),
            'details': data['details'],
            'stats': data['stats'],
            'user_modified': data.get('user_modified', False)
        }
    
    # ========================================
    # ë‹¨ê³„ 4: ë§í’ì„  ì œê±° (ì„ íƒì )
    # ========================================
    
    def remove_speech_bubbles(self, cut_files, output_dir, prompt=None, delay=1):
        """ë§í’ì„  ì œê±° (API í˜¸ì¶œ)"""
        print("\n" + "=" * 60)
        print("ë‹¨ê³„ 4: ë§í’ì„  ì œê±° (API)")
        print("=" * 60)
        
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if isinstance(cut_files, (str, Path)):
            cut_files = [cut_files]
        
        prompt_text = prompt or DEFAULT_PROMPT
        
        print(f"ëª¨ë¸: {self.model_name}")
        print(f"ì²˜ë¦¬: {len(cut_files)}ê°œ ì»·")
        print(f"ë”œë ˆì´: {delay}ì´ˆ")
        
        results = []
        success_count = 0
        
        for i, cut_file in enumerate(cut_files, 1):
            cut_path = Path(cut_file)
            filename = cut_path.name
            
            print(f"\n[{i}/{len(cut_files)}] {filename}")
            
            try:
                start_time = time.time()
                
                # ì´ë¯¸ì§€ ë¡œë“œ (ë°”ì´íŠ¸ë¡œ ì½ê¸°)
                with open(cut_path, 'rb') as f:
                    img_data = f.read()
                
                # MIME íƒ€ì… ê²°ì •
                mime_type = "image/png"
                if filename.lower().endswith('.jpg') or filename.lower().endswith('.jpeg'):
                    mime_type = "image/jpeg"
                
                # API í˜¸ì¶œ
                response = None
                last_error = None
                max_retries = 3
                
                for retry in range(max_retries):
                    try:
                        response = self.client.models.generate_content(
                            model=self.model_name,
                            contents=[
                                types.Content(
                                    role="user",
                                    parts=[
                                        types.Part.from_bytes(data=img_data, mime_type=mime_type),
                                        types.Part(text=prompt_text)
                                    ]
                                )
                            ],
                            config=types.GenerateContentConfig(
                                response_modalities=['IMAGE', 'TEXT']
                            )
                        )
                        break
                    except Exception as api_error:
                        last_error = api_error
                        error_str = str(api_error).lower()
                        
                        if '500' in error_str or 'internal' in error_str:
                            wait_time = (retry + 1) * 5
                            print(f"  âš ï¸ ì„œë²„ ì˜¤ë¥˜, {wait_time}ì´ˆ í›„ ì¬ì‹œë„ ({retry + 1}/{max_retries})")
                            time.sleep(wait_time)
                        else:
                            raise api_error
                
                if response is None:
                    raise last_error if last_error else Exception("API ì‘ë‹µ ì—†ìŒ")
                
                elapsed = time.time() - start_time
                
                # ë””ë²„ê¹…: ì‘ë‹µ êµ¬ì¡° ì¶œë ¥
                print(f"  [DEBUG] response type: {type(response)}")
                print(f"  [DEBUG] response attrs: {[a for a in dir(response) if not a.startswith('_')][:15]}")
                
                # ì‘ë‹µ ì²˜ë¦¬ - ë‹¤ì–‘í•œ ë°©ì‹ ì‹œë„
                result_image = None
                
                # ë°©ë²• 1: response.parts ì§ì ‘ ì ‘ê·¼ (ìµœì‹  API)
                if hasattr(response, 'parts') and response.parts:
                    print(f"  [DEBUG] response.parts ë°œê²¬: {len(response.parts)}ê°œ")
                    for part in response.parts:
                        print(f"  [DEBUG] part type: {type(part)}, attrs: {[a for a in dir(part) if not a.startswith('_')][:10]}")
                        # inline_data (snake_case)
                        if hasattr(part, 'inline_data') and part.inline_data:
                            print(f"  [DEBUG] inline_data ë°œê²¬")
                            image_data = part.inline_data.data
                            result_image = Image.open(BytesIO(image_data))
                            break
                        # inlineData (camelCase)
                        if hasattr(part, 'inlineData') and part.inlineData:
                            print(f"  [DEBUG] inlineData ë°œê²¬")
                            image_data = part.inlineData.data
                            result_image = Image.open(BytesIO(image_data))
                            break
                
                # ë°©ë²• 2: response.candidates ì ‘ê·¼ (ê¸°ì¡´ ë°©ì‹)
                if result_image is None and hasattr(response, 'candidates') and response.candidates:
                    print(f"  [DEBUG] candidates ë°œê²¬: {len(response.candidates)}ê°œ")
                    candidate = response.candidates[0]
                    print(f"  [DEBUG] candidate attrs: {[a for a in dir(candidate) if not a.startswith('_')][:10]}")
                    
                    # finish_reason í™•ì¸ (IMAGE_RECITATION ë“±)
                    finish_reason = getattr(candidate, 'finish_reason', None)
                    finish_reason_str = str(finish_reason) if finish_reason else ''
                    print(f"  [DEBUG] finish_reason: {finish_reason_str}")
                    
                    # ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ ì¼€ì´ìŠ¤ - ì›ë³¸ ë³µì‚¬
                    # IMAGE_RECITATION: ì €ì‘ê¶Œ ê´€ë ¨
                    # PROHIBITED_CONTENT: ì½˜í…ì¸  ì •ì±… ìœ„ë°˜
                    # SAFETY: ì•ˆì „ í•„í„°
                    # BLOCKLIST: ì°¨ë‹¨ ëª©ë¡
                    skip_reasons = ['IMAGE_RECITATION', 'PROHIBITED_CONTENT', 'SAFETY', 'BLOCKLIST', 'OTHER']
                    should_copy_original = (
                        candidate.content is None or 
                        any(reason in finish_reason_str for reason in skip_reasons)
                    )
                    
                    if should_copy_original:
                        print(f"  âš ï¸ API ì œí•œ ({finish_reason_str or 'content None'}) - ì›ë³¸ ë³µì‚¬")
                        out_filename = filename.replace('.png', '_nobubble.png')
                        out_path = output_dir / out_filename
                        shutil.copy2(cut_file, str(out_path))
                        
                        results.append({
                            'input': cut_file,
                            'output': str(out_path),
                            'success': True,
                            'time': time.time() - start_time,
                            'note': 'original_copy'
                        })
                        success_count += 1
                        continue
                    
                    # content.partsì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
                    if hasattr(candidate, 'content') and candidate.content:
                        print(f"  [DEBUG] content attrs: {[a for a in dir(candidate.content) if not a.startswith('_')][:10]}")
                        if hasattr(candidate.content, 'parts') and candidate.content.parts:
                            print(f"  [DEBUG] content.parts ë°œê²¬: {len(candidate.content.parts)}ê°œ")
                            for part in candidate.content.parts:
                                print(f"  [DEBUG] content.part type: {type(part)}")
                                # inline_data (snake_case)
                                if hasattr(part, 'inline_data') and part.inline_data:
                                    print(f"  [DEBUG] content.part.inline_data ë°œê²¬")
                                    image_data = part.inline_data.data
                                    result_image = Image.open(BytesIO(image_data))
                                    break
                                # inlineData (camelCase)  
                                if hasattr(part, 'inlineData') and part.inlineData:
                                    print(f"  [DEBUG] content.part.inlineData ë°œê²¬")
                                    image_data = part.inlineData.data
                                    result_image = Image.open(BytesIO(image_data))
                                    break
                                # text í™•ì¸
                                if hasattr(part, 'text') and part.text:
                                    print(f"  [DEBUG] text ë°œê²¬: {part.text[:100]}...")
                
                # ë°©ë²• 3: response.textê°€ ìˆìœ¼ë©´ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨
                if result_image is None and hasattr(response, 'text') and response.text:
                    print(f"  [DEBUG] response.text: {response.text[:200]}...")
                
                if result_image is None:
                    raise ValueError("ì‘ë‹µì— ì´ë¯¸ì§€ ì—†ìŒ")
                
                out_filename = filename.replace('.png', '_nobubble.png')
                out_path = output_dir / out_filename
                result_image.save(str(out_path))
                
                print(f"  âœ“ ì™„ë£Œ: {out_filename} ({elapsed:.1f}ì´ˆ)")
                
                results.append({
                    'input': cut_file,
                    'output': str(out_path),
                    'success': True,
                    'time': elapsed
                })
                
                success_count += 1
                self.stats['bubbles_removed'] += 1
                self.stats['api_calls'] += 1
                
                if i < len(cut_files) and delay > 0:
                    time.sleep(delay)
                
            except Exception as e:
                err_msg = str(e)
                print(f"  âœ— ì˜¤ë¥˜: {err_msg[:150]}")
                self.stats['errors'].append(f"{filename}: {err_msg}")
                results.append({
                    'input': cut_file,
                    'output': None,
                    'success': False,
                    'error': err_msg
                })
        
        print(f"\nâœ“ ì™„ë£Œ: {success_count}/{len(cut_files)} ì„±ê³µ")
        return results
    
    def remove_speech_bubbles_selective(self, cuts_dir, output_dir, 
                                         classification, 
                                         prompt=None, delay=1,
                                         progress_callback=None):
        """
        ë¶„ë¥˜ ê¸°ë°˜ ì„ íƒì  ë§í’ì„  ì œê±°
        
        Args:
            cuts_dir: ì»· ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            classification: ë¶„ë¥˜ ê²°ê³¼ (process, skip_sfx_only, skip_no_bubble ë¦¬ìŠ¤íŠ¸)
            prompt: API í”„ë¡¬í”„íŠ¸
            delay: API í˜¸ì¶œ ê°„ê²©
            progress_callback: ì§„í–‰ ì½œë°± í•¨ìˆ˜ (current, total, filename, action)
        
        Returns:
            results: ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        print("\n" + "=" * 60)
        print("ë‹¨ê³„ 4: ì„ íƒì  ë§í’ì„  ì œê±°")
        print("=" * 60)
        
        cuts_dir = Path(cuts_dir)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        api_targets = classification.get('process', [])
        skip_sfx = classification.get('skip_sfx_only', [])
        skip_no_bubble = classification.get('skip_no_bubble', [])
        skip_no_text = classification.get('skip_no_text', [])
        skip_all = skip_sfx + skip_no_bubble + skip_no_text
        
        total_files = len(api_targets) + len(skip_all)
        
        print(f"API í˜¸ì¶œ ëŒ€ìƒ: {len(api_targets)}ê°œ")
        print(f"ì›ë³¸ ë³µì‚¬ ëŒ€ìƒ: {len(skip_all)}ê°œ")
        
        results = []
        current = 0
        
        # 1. ìŠ¤í‚µ ëŒ€ìƒ â†’ ì›ë³¸ ë³µì‚¬
        for skip_file in skip_all:
            current += 1
            src = cuts_dir / skip_file
            dst = output_dir / skip_file.replace('.png', '_nobubble.png')
            
            if src.exists():
                shutil.copy2(src, dst)
                results.append({
                    'input': str(src),
                    'output': str(dst),
                    'success': True,
                    'action': 'copy',
                    'time': 0
                })
                self.stats['api_skipped'] += 1
                print(f"  [{current}/{total_files}] {skip_file} â†’ ë³µì‚¬")
                
                if progress_callback:
                    progress_callback(current, total_files, skip_file, 'copy')
        
        # 2. API í˜¸ì¶œ ëŒ€ìƒ â†’ Gemini API
        if api_targets:
            api_files = [str(cuts_dir / f) for f in api_targets]
            
            for idx, cut_file in enumerate(api_files):
                current += 1
                filename = Path(cut_file).name
                
                if progress_callback:
                    progress_callback(current, total_files, filename, 'api')
                
                try:
                    api_result = self.remove_speech_bubbles(
                        [cut_file], str(output_dir),
                        prompt=prompt,
                        delay=delay if idx < len(api_files) - 1 else 0
                    )
                    results.extend(api_result)
                except Exception as e:
                    results.append({
                        'input': cut_file,
                        'output': None,
                        'success': False,
                        'action': 'api',
                        'error': str(e)
                    })
        
        # í†µê³„
        success_count = sum(1 for r in results if r.get('success', False))
        
        print(f"\nâœ“ ì„ íƒì  ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   API í˜¸ì¶œ: {len(api_targets)}ê°œ")
        print(f"   ì›ë³¸ ë³µì‚¬: {len(skip_all)}ê°œ")
        print(f"   ì„±ê³µ: {success_count}/{total_files}ê°œ")
        
        return results
    
    # ========================================
    # ì „ì²´ íŒŒì´í”„ë¼ì¸
    # ========================================
    
    def run(self, input_path, output_base_dir, 
            dpi=300, min_gap_height=150,
            quality_threshold=0.8, std_threshold=15,
            min_cut_height=200,
            remove_empty_edges=True,
            api_prompt=None, api_delay=1,
            use_pre_classification=True,
            yolo_model_path=None):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            use_pre_classification: ì‚¬ì „ ë¶„ë¥˜ ì‚¬ìš© ì—¬ë¶€
            yolo_model_path: YOLO ëª¨ë¸ ê²½ë¡œ
        """
        self.stats['start_time'] = datetime.now()
        
        print("\n" + "=" * 60)
        print("ğŸ¨ ì›¹íˆ° ìë™ ì²˜ë¦¬ (Google Gemini API)")
        print("=" * 60)
        print(f"ì…ë ¥: {input_path}")
        print(f"ì¶œë ¥: {output_base_dir}")
        print(f"ëª¨ë¸: {self.model_name}")
        print(f"ì‚¬ì „ ë¶„ë¥˜: {'ì‚¬ìš©' if use_pre_classification else 'ë¯¸ì‚¬ìš©'}")
        
        output_base_dir = Path(output_base_dir)
        output_base_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # ë‹¨ê³„ 1: ì…ë ¥ â†’ PNG
            png_dir = output_base_dir / "1_png"
            png_files = self.convert_to_png(input_path, png_dir, dpi=dpi)
            
            # ë‹¨ê³„ 2: PNG â†’ ì»· ë¶„ë¦¬
            cuts_dir = output_base_dir / "2_cuts"
            cut_files = self.split_into_cuts(
                png_files, cuts_dir,
                min_gap_height=min_gap_height,
                quality_threshold=quality_threshold,
                std_threshold=std_threshold,
                min_cut_height=min_cut_height,
                remove_empty_edges=remove_empty_edges
            )
            
            # ë‹¨ê³„ 3: ì‚¬ì „ ë¶„ë¥˜ (ì„ íƒì )
            final_dir = output_base_dir / "3_final"
            
            if use_pre_classification and HAS_BUBBLE_PROCESSOR:
                analysis = self.analyze_cuts_for_bubble(
                    cuts_dir,
                    model_path=yolo_model_path
                )
                
                if analysis:
                    self.save_analysis_result(cuts_dir, analysis)
                    
                    # ë‹¨ê³„ 4: ì„ íƒì  ë§í’ì„  ì œê±°
                    results = self.remove_speech_bubbles_selective(
                        cuts_dir, final_dir,
                        classification=analysis,
                        prompt=api_prompt,
                        delay=api_delay
                    )
                else:
                    # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì „ì²´ ì²˜ë¦¬
                    results = self.remove_speech_bubbles(
                        cut_files, final_dir,
                        prompt=api_prompt,
                        delay=api_delay
                    )
            else:
                # ì‚¬ì „ ë¶„ë¥˜ ë¯¸ì‚¬ìš© ì‹œ ì „ì²´ ì²˜ë¦¬
                results = self.remove_speech_bubbles(
                    cut_files, final_dir,
                    prompt=api_prompt,
                    delay=api_delay
                )
            
            self.stats['end_time'] = datetime.now()
            
            self._save_report(output_base_dir, results)
            
            print("\n" + "=" * 60)
            print("âœ“ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print("=" * 60)
            self._print_summary()
            
            return results
            
        except Exception as e:
            self.stats['end_time'] = datetime.now()
            print(f"\nâœ— ì˜¤ë¥˜: {e}")
            raise
    
    def _save_report(self, output_dir, results):
        report = {
            'timestamp': datetime.now().isoformat(),
            'model': self.model_name,
            'stats': {
                'input_files': self.stats['input_files'],
                'png_files': self.stats['png_files'],
                'cuts_total': self.stats['cuts_total'],
                'bubbles_removed': self.stats['bubbles_removed'],
                'api_calls': self.stats['api_calls'],
                'api_skipped': self.stats['api_skipped'],
                'errors': len(self.stats['errors'])
            },
            'error_details': self.stats['errors']
        }
        
        report_path = output_dir / 'report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
    
    def _print_summary(self):
        print(f"\nğŸ“Š ìš”ì•½:")
        print(f"  ëª¨ë¸: {self.model_name}")
        print(f"  ì…ë ¥: {self.stats['input_files']}ê°œ íŒŒì¼")
        print(f"  PNG: {self.stats['png_files']}ê°œ")
        print(f"  ì»·: {self.stats['cuts_total']}ê°œ")
        print(f"  API í˜¸ì¶œ: {self.stats['api_calls']}ê°œ")
        print(f"  API ìŠ¤í‚µ: {self.stats['api_skipped']}ê°œ")
        print(f"  ì²˜ë¦¬: {self.stats['bubbles_removed']}ê°œ")
        print(f"  ì˜¤ë¥˜: {len(self.stats['errors'])}ê°œ")
        
        if self.stats['start_time'] and self.stats['end_time']:
            duration = self.stats['end_time'] - self.stats['start_time']
            print(f"  ì‹œê°„: {duration}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ì›¹íˆ° ìë™ ì²˜ë¦¬ (Google Gemini API)')
    parser.add_argument('input_path', help='ì…ë ¥ íŒŒì¼ (PDF/PSD/PSB/PNG)')
    parser.add_argument('-o', '--output', default='./webtoon_output')
    parser.add_argument('--api-key', help='Google AI Studio API í‚¤')
    parser.add_argument('--model', choices=['flash', 'pro'], default='flash')
    parser.add_argument('--dpi', type=int, default=300)
    parser.add_argument('--min-gap', type=int, default=150, help='ìµœì†Œ ì—¬ë°± ë†’ì´ (ê¸°ë³¸: 150px)')
    parser.add_argument('--min-cut', type=int, default=200, help='ìµœì†Œ ì»· ë†’ì´ (ê¸°ë³¸: 200px)')
    parser.add_argument('--quality', type=float, default=0.8)
    parser.add_argument('--std-threshold', type=int, default=15)
    parser.add_argument('--delay', type=int, default=1)
    parser.add_argument('--no-pre-classify', action='store_true', help='ì‚¬ì „ ë¶„ë¥˜ ë¹„í™œì„±í™”')
    parser.add_argument('--yolo-model', type=str, default=None, help='YOLO ëª¨ë¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    pipeline = WebtoonPipelineGoogle(
        google_api_key=args.api_key,
        model=args.model
    )
    
    pipeline.run(
        input_path=args.input_path,
        output_base_dir=args.output,
        dpi=args.dpi,
        min_gap_height=args.min_gap,
        min_cut_height=args.min_cut,
        quality_threshold=args.quality,
        std_threshold=args.std_threshold,
        api_delay=args.delay,
        use_pre_classification=not args.no_pre_classify,
        yolo_model_path=args.yolo_model
    )


if __name__ == "__main__":
    main()
